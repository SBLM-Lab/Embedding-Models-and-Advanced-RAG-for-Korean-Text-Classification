{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from transformers import (BertModel, BertTokenizer, ElectraModel, ElectraTokenizer)\n",
    "from kobert_transformers import get_tokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# cache_dir = os.path.expanduser(\"~/.cache/huggingface\")\n",
    "# if os.path.exists(cache_dir):\n",
    "#     shutil.rmtree(cache_dir)\n",
    "#     print(\"Hugging Face 캐시 삭제 완료.\")\n",
    "# else:\n",
    "#     print(\"Hugging Face 캐시가 이미 삭제되었거나 존재하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"민원_train.csv\", encoding=\"utf-8\")\n",
    "test_df = pd.read_csv(\"민원_validation.csv\", encoding=\"utf-8\")\n",
    "\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "combined_df = combined_df.drop_duplicates(subset=\"Q_refined\", keep=\"first\")\n",
    "\n",
    "min_threshold = 1600\n",
    "fixed_sample_size = 1600\n",
    "\n",
    "balanced_df = pd.DataFrame()\n",
    "category_counts = combined_df['predication'].value_counts()\n",
    "\n",
    "for category, count in category_counts.items():\n",
    "    subset = combined_df[combined_df['predication'] == category]\n",
    "    if count < min_threshold:\n",
    "        continue  \n",
    "    else:\n",
    "        subset = subset.sample(fixed_sample_size, random_state=42)\n",
    "    balanced_df = pd.concat([balanced_df, subset])\n",
    "\n",
    "test_size = 1000\n",
    "train_data, test_data = train_test_split(balanced_df, test_size=test_size, stratify=balanced_df['predication'], random_state=seed)\n",
    "\n",
    "val_size = 200\n",
    "train_data, validation_data = train_test_split(train_data, test_size=val_size, stratify=train_data['predication'], random_state=seed)\n",
    "\n",
    "train = train_data.copy()\n",
    "validation = validation_data.copy()\n",
    "test = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Jina-v3\n",
    "class JinaEmbedding:\n",
    "    def __init__(self, model_name=\"jinaai/jina-embeddings-v3\"):\n",
    "        self.model = SentenceTransformer(model_name, trust_remote_code=True).to(device)\n",
    "        \n",
    "    def embed_documents(self, texts):\n",
    "        embeddings = self.model.encode(texts, convert_to_numpy=True)\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.embed_documents([text])[0]\n",
    "\n",
    "# KoBERT\n",
    "class KoBERTEmbedding:\n",
    "    def __init__(self, model_name=\"monologg/kobert\"): \n",
    "        self.tokenizer = get_tokenizer()\n",
    "        self.model = BertModel.from_pretrained(model_name).to(device)\n",
    "        \n",
    "    def embed_documents(self, texts):\n",
    "        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings = embeddings.numpy()\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.embed_documents([text])[0]\n",
    "\n",
    "# KoELECTRA\n",
    "class KoELECTRAEmbedding:\n",
    "    def __init__(self, model_name=\"monologg/koelectra-base-v3-discriminator\"):\n",
    "        self.tokenizer = ElectraTokenizer.from_pretrained(model_name)\n",
    "        self.model = ElectraModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        inputs = self.tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings = embeddings.numpy()\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.embed_documents([text])[0]\n",
    "\n",
    "# KURE-V1\n",
    "class KUREEmbedding:\n",
    "    def __init__(self, model_name=\"nlpai-lab/KURE-v1\"):\n",
    "        self.model = SentenceTransformer(model_name, trust_remote_code=True).to(device)\n",
    "        \n",
    "    def embed_documents(self, texts):\n",
    "        embeddings = self.model.encode(texts, convert_to_numpy=True)\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self.embed_documents([text])[0]\n",
    "\n",
    "# KoE5\n",
    "class KoE5Embedding(KUREEmbedding):\n",
    "    def __init__(self, model_name=\"nlpai-lab/KoE5\"):\n",
    "        super().__init__(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODELS = {\n",
    "    \"text-embedding-3-small\": OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    "    \"text-embedding-ada-002\": OpenAIEmbeddings(),\n",
    "    \"jina-v3\": JinaEmbedding(),\n",
    "    \"kobert\": KoBERTEmbedding(),\n",
    "    \"koelectra\": KoELECTRAEmbedding(),\n",
    "    \"kure-v1\": KUREEmbedding(),\n",
    "    \"koe5\": KoE5Embedding()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creat Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorstore(df, embedding_model, seed):\n",
    "\n",
    "    texts = df[\"Q_refined\"].tolist()\n",
    "    labels = df[\"predication\"].tolist()\n",
    "    docs = [f\"{text} (Label: {label})\" for text, label in zip(texts, labels)]\n",
    "\n",
    "    model = EMBEDDING_MODELS[embedding_model]\n",
    "\n",
    "    batch_size = 16 \n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(0, len(docs), batch_size):\n",
    "        batch = docs[i : i + batch_size]\n",
    "        batch_embeddings = model.embed_documents(batch)\n",
    "        embeddings.extend(batch_embeddings)\n",
    "\n",
    "    text_embedding_pairs = list(zip(docs, embeddings))\n",
    "    vectorstore = FAISS.from_embeddings(text_embedding_pairs, model)\n",
    "\n",
    "    folder_path = \"embedding_comparison2\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    save_path = os.path.join(folder_path, f\"faiss_index_{embedding_model}_seed{seed}\")\n",
    "    vectorstore.save_local(save_path)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_vectorstores():\n",
    "    for model_name in EMBEDDING_MODELS.keys():\n",
    "        create_vectorstore(train, model_name, seed)\n",
    "\n",
    "create_all_vectorstores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectorstore(embedding_model, seed):\n",
    "    load_path = f\"embedding_comparison/faiss_index_{embedding_model}_seed{seed}\"\n",
    "    \n",
    "    if not os.path.exists(load_path):\n",
    "        raise FileNotFoundError(f\"Cannot find Vectorstore: {load_path}\")\n",
    "\n",
    "    return FAISS.load_local(load_path, EMBEDDING_MODELS[embedding_model].embed_query, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_retrieval(df_test, embedding_model, seed, k_values=[1, 3, 5, 10]):\n",
    "    vectorstore = load_vectorstore(embedding_model, seed)\n",
    "\n",
    "    results = {k: {\"Recall\": 0, \"MRR\": 0} for k in k_values}\n",
    "    reciprocal_ranks = {k: [] for k in k_values}\n",
    "    recall_counts = {k: 0 for k in k_values}\n",
    "    \n",
    "    for query, true_label in tqdm(zip(df_test[\"Q_refined\"], df_test[\"predication\"]), total=len(df_test), desc=\"Evaluating\"):\n",
    "        similar_docs = vectorstore.similarity_search(query, k=max(k_values))\n",
    "        retrieved_labels = [doc.page_content.split(\"(Label: \")[-1].strip(\")\") for doc in similar_docs]\n",
    "        \n",
    "        for k in k_values:\n",
    "            top_k_labels = retrieved_labels[:k]\n",
    "            if true_label in top_k_labels:\n",
    "                recall_counts[k] += 1\n",
    "                rank = top_k_labels.index(true_label) + 1\n",
    "                reciprocal_ranks[k].append(1 / rank)\n",
    "            else:\n",
    "                reciprocal_ranks[k].append(0)\n",
    "    \n",
    "    for k in k_values:\n",
    "        results[k][\"Recall\"] = recall_counts[k] / len(df_test)\n",
    "        results[k][\"MRR\"] = np.mean(reciprocal_ranks[k])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for model_name in EMBEDDING_MODELS.keys():\n",
    "    model_results = evaluate_model_retrieval(test, model_name, seed, k_values=[1, 3, 5, 10])\n",
    "    results[model_name] = model_results\n",
    "\n",
    "final_results = []\n",
    "for model_name, metrics in results.items():\n",
    "    recall_values = {f\"Recall@{k}\": metrics[k][\"Recall\"] for k in [1, 3, 5, 10]}\n",
    "    mrr_values = {f\"MRR@{k}\": metrics[k][\"MRR\"] for k in [1, 3, 5, 10]}\n",
    "\n",
    "    final_results.append({\n",
    "        \"Seed\": seed,\n",
    "        \"Model\": model_name,\n",
    "        **recall_values,\n",
    "        **mrr_values\n",
    "    })\n",
    "\n",
    "final_results = pd.DataFrame(final_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
